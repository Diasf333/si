{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab206a09",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9219846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from si.io.csv_file import read_csv\n",
    "from si.model_selection.split import stratified_train_test_split\n",
    "\n",
    "\n",
    "from si.io.csv_file import read_csv              \n",
    "from si.model_selection.split import train_test_split\n",
    "from si.feature_selection.select_percentile import SelectPercentile\n",
    "from si.statistics.f_classification import f_classification\n",
    "from si.models.knn_classifier import KNNClassifier\n",
    "from si.metrics.accuracy import accuracy\n",
    "\n",
    "from si.io.csv_file import read_csv\n",
    "from si.decomposition.pca import PCA\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from si.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ecd33",
   "metadata": {},
   "source": [
    "### EX 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7d9c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv(\"../datasets/iris/iris.csv\", sep = \",\", features = True, label = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1252673f",
   "metadata": {},
   "source": [
    "### EX 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca0501ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "penul_var = dataset.X[:,-2]\n",
    "\n",
    "print(penul_var.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84168ac6",
   "metadata": {},
   "source": [
    "### EX 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf51583d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.45, 3.03, 5.33, 2.17])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_10_sample = dataset.X[-10:]\n",
    "\n",
    "print(last_10_sample)\n",
    "\n",
    "np.nanmean(last_10_sample, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2d1b57",
   "metadata": {},
   "source": [
    "### EX 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63baa6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "less_equal_6 = np.all(dataset.X <= 6, axis=1) \n",
    "\n",
    "print(np.count_nonzero(less_equal_6==True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd7801",
   "metadata": {},
   "source": [
    "### EX 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2545025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "mask = dataset.y !='Iris-setosa'\n",
    "\n",
    "print(np.count_nonzero(dataset.y[mask]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03c0340",
   "metadata": {},
   "source": [
    "### EX 2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d0e065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropna:\n",
      "Shape: (3, 2)\n",
      "X:\n",
      " [[ 1.  2.]\n",
      " [nan  3.]\n",
      " [ 4.  5.]]\n",
      "\n",
      "After dropna:\n",
      "Shape: (2, 2)\n",
      "X:\n",
      " [[1. 2.]\n",
      " [4. 5.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create dataset with NaN values\n",
    "dataset = Dataset(\n",
    "    X=np.array([[1.0, 2.0], [np.nan, 3.0], [4.0, 5.0]]),\n",
    "    y=np.array([0, 1, 0]),\n",
    "    features=[\"feat1\", \"feat2\"],\n",
    "    label=\"y\"\n",
    ")\n",
    "\n",
    "print(\"Before dropna:\")\n",
    "print(\"Shape:\", dataset.X.shape)\n",
    "print(\"X:\\n\", dataset.X)\n",
    "\n",
    "dataset.dropna()\n",
    "\n",
    "print(\"\\nAfter dropna:\")\n",
    "print(\"Shape:\", dataset.X.shape)\n",
    "print(\"X:\\n\", dataset.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26300852",
   "metadata": {},
   "source": [
    "### EX 2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd3ff424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before fillna('mean'):\n",
      "X:\n",
      " [[ 1.  2.]\n",
      " [nan  3.]\n",
      " [ 4.  5.]]\n",
      "\n",
      "After fillna('mean'):\n",
      "X:\n",
      " [[1.  2. ]\n",
      " [2.5 3. ]\n",
      " [4.  5. ]]\n"
     ]
    }
   ],
   "source": [
    "# Create dataset with NaN values\n",
    "dataset = Dataset(\n",
    "    X=np.array([[1.0, 2.0], [np.nan, 3.0], [4.0, 5.0]]),\n",
    "    y=np.array([0, 1, 0]),\n",
    "    features=[\"feat1\", \"feat2\"],\n",
    "    label=\"y\"\n",
    ")\n",
    "\n",
    "print(\"Before fillna('mean'):\")\n",
    "print(\"X:\\n\", dataset.X)\n",
    "\n",
    "dataset.fillna(\"mean\")\n",
    "\n",
    "print(\"\\nAfter fillna('mean'):\")\n",
    "print(\"X:\\n\", dataset.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6dade8",
   "metadata": {},
   "source": [
    "### EX 2.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7abde858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before remove_by_index(1):\n",
      "Shape: (3, 2)\n",
      "y: [0 1 0]\n",
      "\n",
      "After remove_by_index(1):\n",
      "Shape: (2, 2)\n",
      "y: [0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create dataset\n",
    "dataset = Dataset(\n",
    "    X=np.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]),\n",
    "    y=np.array([0, 1, 0]),\n",
    "    features=[\"feat1\", \"feat2\"],\n",
    "    label=\"y\"\n",
    ")\n",
    "\n",
    "print(\"Before remove_by_index(1):\")\n",
    "print(\"Shape:\", dataset.X.shape)\n",
    "print(\"y:\", dataset.y)\n",
    "\n",
    "dataset.remove_by_index(1)\n",
    "\n",
    "print(\"\\nAfter remove_by_index(1):\")\n",
    "print(\"Shape:\", dataset.X.shape)\n",
    "print(\"y:\", dataset.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e989c19",
   "metadata": {},
   "source": [
    "### EX 3.3 - Select Percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be228f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SelectPercentile + KNN: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 1) Load iris.csv into a Dataset\n",
    "dataset = read_csv(\"../datasets/iris/iris.csv\", sep = \",\", features = True, label = True )\n",
    "\n",
    "# 2) Stratified train/test split\n",
    "train_ds, test_ds = train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3) Fit SelectPercentile on the training set\n",
    "selector = SelectPercentile(score_func=f_classification, percentile=50)\n",
    "selector.fit(train_ds)\n",
    "\n",
    "# 4) Transform X and build new Dataset objects\n",
    "X_train_sel = selector.transform(train_ds)   # np.ndarray with selected features\n",
    "X_test_sel = selector.transform(test_ds)\n",
    "\n",
    "train_reduced = Dataset(X=X_train_sel, y=train_ds.y, features=None, label=train_ds.label)\n",
    "test_reduced = Dataset(X=X_test_sel, y=test_ds.y, features=None, label=test_ds.label)\n",
    "\n",
    "# 5) Train KNN on reduced dataset\n",
    "knn = KNNClassifier(k=5)\n",
    "knn.fit(train_reduced)\n",
    "\n",
    "# 6) Evaluate\n",
    "y_pred = knn.predict(test_reduced)\n",
    "score = accuracy(test_reduced.y, y_pred)\n",
    "print(\"Accuracy with SelectPercentile + KNN:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd34e716",
   "metadata": {},
   "source": [
    "### EX 5.2 - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4701296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (150, 4)\n",
      "Reduced shape: (150, 2)\n",
      "Explained variance (2 comps): [0.92461621 0.05301557]\n"
     ]
    }
   ],
   "source": [
    "# 1) Load iris.csv as Dataset\n",
    "dataset = read_csv(\"../datasets/iris/iris.csv\", sep = \",\", features = True, label = True )\n",
    "\n",
    "# 2) Fit PCA with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(dataset)\n",
    "\n",
    "# 3) Transform dataset\n",
    "X_reduced = pca.transform(dataset)\n",
    "\n",
    "print(\"Original shape:\", dataset.X.shape)\n",
    "print(\"Reduced shape:\", X_reduced.shape)\n",
    "print(\"Explained variance (2 comps):\", pca.explained_variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8906d8",
   "metadata": {},
   "source": [
    "### EX 6.2 - Stratified Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78bb5797",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m dataset = read_csv(\u001b[33m\"\u001b[39m\u001b[33m../datasets/iris/iris.csv\u001b[39m\u001b[33m\"\u001b[39m, sep = \u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m, features = \u001b[38;5;28;01mTrue\u001b[39;00m, label = \u001b[38;5;28;01mTrue\u001b[39;00m )  \n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 2. Separate features and labels\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Adjust column names to match your CSV format\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m X = \u001b[43mdf\u001b[49m.drop(\u001b[33m\"\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m\"\u001b[39m, axis=\u001b[32m1\u001b[39m).to_numpy()\n\u001b[32m     13\u001b[39m y = df[\u001b[33m\"\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m\"\u001b[39m].to_numpy()\n\u001b[32m     14\u001b[39m features = df.drop(\u001b[33m\"\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m\"\u001b[39m, axis=\u001b[32m1\u001b[39m).columns.tolist()\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Load the iris.csv (adapt path if needed)\n",
    "# Example uses standard iris CSV format with columns: sepal.length, sepal.width, petal.length, petal.width, class\n",
    "dataset = read_csv(\"../datasets/iris/iris.csv\", sep = \",\", features = True, label = True )  \n",
    "\n",
    "# 2. Separate features and labels\n",
    "# Adjust column names to match your CSV format\n",
    "X = df.drop(\"class\", axis=1).to_numpy()\n",
    "y = df[\"class\"].to_numpy()\n",
    "features = df.drop(\"class\", axis=1).columns.tolist()\n",
    "label = \"class\"\n",
    "\n",
    "# 3. Wrap in your Dataset object\n",
    "iris_dataset = Dataset(X, y, features, label)\n",
    "\n",
    "# 4. Split using your function\n",
    "train, test = stratified_train_test_split(iris_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Print class distribution to check stratification\n",
    "train_classes, train_counts = np.unique(train.y, return_counts=True)\n",
    "test_classes, test_counts = np.unique(test.y, return_counts=True)\n",
    "\n",
    "print(\"Train set class distribution:\")\n",
    "for cls, count in zip(train_classes, train_counts):\n",
    "    print(f\"{cls}: {count}\")\n",
    "    \n",
    "print(\"\\nTest set class distribution:\")\n",
    "for cls, count in zip(test_classes, test_counts):\n",
    "    print(f\"{cls}: {count}\")\n",
    "\n",
    "print(\"\\nTrain size:\", len(train.y))\n",
    "print(\"Test size:\", len(test.y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eefbef",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class RandomForestClassifier without an implementation for abstract methods '_fit', '_predict', '_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m iris = read_csv(\u001b[33m\"\u001b[39m\u001b[33m../datasets/iris/iris.csv\u001b[39m\u001b[33m\"\u001b[39m, sep=\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m, features=\u001b[38;5;28;01mTrue\u001b[39;00m, label=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      6\u001b[39m train_ds, test_ds = train_test_split(iris, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m rf = \u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnestimators\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaxfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mminsamplesplit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaxdepth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m rf.fit(train_ds)\n\u001b[32m     18\u001b[39m score = rf.score(test_ds)\n",
      "\u001b[31mTypeError\u001b[39m: Can't instantiate abstract class RandomForestClassifier without an implementation for abstract methods '_fit', '_predict', '_score'"
     ]
    }
   ],
   "source": [
    "from si.io.csv_file import read_csv\n",
    "from si.model_selection.split import train_test_split\n",
    "from si.models.random_forest_classifier import RandomForestClassifier\n",
    "\n",
    "iris = read_csv(\"../datasets/iris/iris.csv\", sep=\",\", features=True, label=True)\n",
    "train_ds, test_ds = train_test_split(iris, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    nestimators=50,\n",
    "    maxfeatures=None,\n",
    "    minsamplesplit=2,\n",
    "    maxdepth=10,\n",
    "    mode=\"gini\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "rf.fit(train_ds)\n",
    "score = rf.score(test_ds)\n",
    "print(\"Accuracy:\", score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
