{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab206a09",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9219846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from si.io.csv_file import read_csv\n",
    "from si.model_selection.split import stratified_train_test_split\n",
    "\n",
    "\n",
    "from si.io.csv_file import read_csv              \n",
    "from si.model_selection.split import train_test_split\n",
    "from si.feature_selection.select_percentile import SelectPercentile\n",
    "from si.statistics.f_classification import f_classification\n",
    "from si.models.knn_classifier import KNNClassifier\n",
    "from si.metrics.accuracy import accuracy\n",
    "\n",
    "from si.io.csv_file import read_csv\n",
    "from si.decomposition.pca import PCA\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from si.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ecd33",
   "metadata": {},
   "source": [
    "### EX 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d9c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv(\"../datasets/iris/iris.csv\", sep = \",\", features = True, label = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1252673f",
   "metadata": {},
   "source": [
    "### EX 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0501ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "penul_var = dataset.X[:,-2]\n",
    "\n",
    "print(penul_var.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84168ac6",
   "metadata": {},
   "source": [
    "### EX 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf51583d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.45, 3.03, 5.33, 2.17])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_10_sample = dataset.X[-10:]\n",
    "\n",
    "print(last_10_sample)\n",
    "\n",
    "np.nanmean(last_10_sample, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2d1b57",
   "metadata": {},
   "source": [
    "### EX 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63baa6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "less_equal_6 = np.all(dataset.X <= 6, axis=1) \n",
    "\n",
    "print(np.count_nonzero(less_equal_6==True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd7801",
   "metadata": {},
   "source": [
    "### EX 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2545025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "mask = dataset.y !='Iris-setosa'\n",
    "\n",
    "print(np.count_nonzero(dataset.y[mask]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03c0340",
   "metadata": {},
   "source": [
    "### EX 2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d0e065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropna:\n",
      "Shape: (3, 2)\n",
      "X:\n",
      " [[ 1.  2.]\n",
      " [nan  3.]\n",
      " [ 4.  5.]]\n",
      "\n",
      "After dropna:\n",
      "Shape: (2, 2)\n",
      "X:\n",
      " [[1. 2.]\n",
      " [4. 5.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create dataset with NaN values\n",
    "dataset = Dataset(\n",
    "    X=np.array([[1.0, 2.0], [np.nan, 3.0], [4.0, 5.0]]),\n",
    "    y=np.array([0, 1, 0]),\n",
    "    features=[\"feat1\", \"feat2\"],\n",
    "    label=\"y\"\n",
    ")\n",
    "\n",
    "print(\"Before dropna:\")\n",
    "print(\"Shape:\", dataset.X.shape)\n",
    "print(\"X:\\n\", dataset.X)\n",
    "\n",
    "dataset.dropna()\n",
    "\n",
    "print(\"\\nAfter dropna:\")\n",
    "print(\"Shape:\", dataset.X.shape)\n",
    "print(\"X:\\n\", dataset.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26300852",
   "metadata": {},
   "source": [
    "### EX 2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd3ff424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before fillna('mean'):\n",
      "X:\n",
      " [[ 1.  2.]\n",
      " [nan  3.]\n",
      " [ 4.  5.]]\n",
      "\n",
      "After fillna('mean'):\n",
      "X:\n",
      " [[1.  2. ]\n",
      " [2.5 3. ]\n",
      " [4.  5. ]]\n"
     ]
    }
   ],
   "source": [
    "# Create dataset with NaN values\n",
    "dataset = Dataset(\n",
    "    X=np.array([[1.0, 2.0], [np.nan, 3.0], [4.0, 5.0]]),\n",
    "    y=np.array([0, 1, 0]),\n",
    "    features=[\"feat1\", \"feat2\"],\n",
    "    label=\"y\"\n",
    ")\n",
    "\n",
    "print(\"Before fillna('mean'):\")\n",
    "print(\"X:\\n\", dataset.X)\n",
    "\n",
    "dataset.fillna(\"mean\")\n",
    "\n",
    "print(\"\\nAfter fillna('mean'):\")\n",
    "print(\"X:\\n\", dataset.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6dade8",
   "metadata": {},
   "source": [
    "### EX 2.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7abde858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before remove_by_index(1):\n",
      "Shape: (3, 2)\n",
      "y: [0 1 0]\n",
      "\n",
      "After remove_by_index(1):\n",
      "Shape: (2, 2)\n",
      "y: [0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create dataset\n",
    "dataset = Dataset(\n",
    "    X=np.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]),\n",
    "    y=np.array([0, 1, 0]),\n",
    "    features=[\"feat1\", \"feat2\"],\n",
    "    label=\"y\"\n",
    ")\n",
    "\n",
    "print(\"Before remove_by_index(1):\")\n",
    "print(\"Shape:\", dataset.X.shape)\n",
    "print(\"y:\", dataset.y)\n",
    "\n",
    "dataset.remove_by_index(1)\n",
    "\n",
    "print(\"\\nAfter remove_by_index(1):\")\n",
    "print(\"Shape:\", dataset.X.shape)\n",
    "print(\"y:\", dataset.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e989c19",
   "metadata": {},
   "source": [
    "### EX 3.3 - Select Percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be228f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SelectPercentile + KNN: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 1) Load iris.csv into a Dataset\n",
    "dataset = read_csv(\"../datasets/iris/iris.csv\", sep = \",\", features = True, label = True )\n",
    "\n",
    "# 2) Stratified train/test split\n",
    "train_ds, test_ds = train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3) Fit SelectPercentile on the training set\n",
    "selector = SelectPercentile(score_func=f_classification, percentile=50)\n",
    "selector.fit(train_ds)\n",
    "\n",
    "# 4) Transform X and build new Dataset objects\n",
    "X_train_sel = selector.transform(train_ds)   # np.ndarray with selected features\n",
    "X_test_sel = selector.transform(test_ds)\n",
    "\n",
    "train_reduced = Dataset(X=X_train_sel, y=train_ds.y, features=None, label=train_ds.label)\n",
    "test_reduced = Dataset(X=X_test_sel, y=test_ds.y, features=None, label=test_ds.label)\n",
    "\n",
    "# 5) Train KNN on reduced dataset\n",
    "knn = KNNClassifier(k=5)\n",
    "knn.fit(train_reduced)\n",
    "\n",
    "# 6) Evaluate\n",
    "y_pred = knn.predict(test_reduced)\n",
    "score = accuracy(test_reduced.y, y_pred)\n",
    "print(\"Accuracy with SelectPercentile + KNN:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd34e716",
   "metadata": {},
   "source": [
    "### EX 5.2 - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4701296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (150, 4)\n",
      "Reduced shape: (150, 2)\n",
      "Explained variance (2 comps): [0.92461621 0.05301557]\n"
     ]
    }
   ],
   "source": [
    "# 1) Load iris.csv as Dataset\n",
    "dataset = read_csv(\"../datasets/iris/iris.csv\", sep = \",\", features = True, label = True )\n",
    "\n",
    "# 2) Fit PCA with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(dataset)\n",
    "\n",
    "# 3) Transform dataset\n",
    "X_reduced = pca.transform(dataset)\n",
    "\n",
    "print(\"Original shape:\", dataset.X.shape)\n",
    "print(\"Reduced shape:\", X_reduced.shape)\n",
    "print(\"Explained variance (2 comps):\", pca.explained_variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ad54a",
   "metadata": {},
   "source": [
    "### EX9 - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74eefbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from si.io.csv_file import read_csv\n",
    "from si.model_selection.split import train_test_split\n",
    "from si.models.random_forest_classifier import RandomForestClassifier\n",
    "\n",
    "iris = read_csv(\"../datasets/iris/iris.csv\", sep=\",\", features=True, label=True)\n",
    "train_ds, test_ds = train_test_split(iris, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    nestimators=50,\n",
    "    maxfeatures=None,\n",
    "    minsamplesplit=2,\n",
    "    maxdepth=10,\n",
    "    mode=\"gini\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "rf.fit(train_ds)\n",
    "score = rf.score(test_ds)\n",
    "print(\"Accuracy:\", score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
